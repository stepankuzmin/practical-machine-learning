---
title: "Predicting how well an activity was performed"
author: "Stepan Kuzmin"
date: '5 июня 2016 г '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify _how much_ of a particular activity they do, but they rarely quantify _how well_ they do it.

The goal of this project is to predict the manner in which 6 participants did the barbell lifts using data from their accelerometers on the belt, forearm, arm, and dumbell.

# Input data

This project uses [Human Activity Recognition Weight Lifting Exercises dataset](http://groupware.les.inf.puc-rio.br/har). Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(caret)
```

```{r, message=FALSE, warning=FALSE, cache=TRUE}
data <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"),  na.strings=c("NA", "#DIV/0!", ""))
data <- tbl_df(data)
dim(data)
```

Remove first 5 columns, that not make any intuitive sense, columns that contains mostly NA's and zero- or near-zero predictors

```{r, message=FALSE, warning=FALSE, cache=TRUE}
newData <- data %>% select(-c((1:5), which(colMeans(is.na(.)) > 0.95), nearZeroVar(data)))
```

Select numeric columns

```{r}
numericData <- newData %>% select(which(sapply(., is.numeric)))
```

Impute missing values using knnImpute

```{r, message=FALSE, warning=FALSE, cache=TRUE}
preprocessedData <- preProcess(numericData, method=c('knnImpute', 'center', 'scale'))
numericData <- predict(preprocessedData, numericData)
processedData <- full_join(newData, numericData)
```

Remove highly correlated variables and all observations with missing predicting variable

```{r, message=FALSE, warning=FALSE, cache=TRUE}
cleanData <- processedData %>% select(-findCorrelation(cor(numericData))) %>% filter(!is.na(classe))
dim(cleanData)
sum(is.na(cleanData$classe))
```

Create cross validation set

```{r}
set.seed(123456)
inTrain <- createDataPartition(y=cleanData$classe, p=0.75, list=F)
training <- cleanData[inTrain, ]
testing <- cleanData[-inTrain, ]
dim(training)
```

# Algorithm

Let's start with a Random Forest model, to see if it would have acceptable performance. Fit the model on `training` dataset, and instruct the `train` function to use 3-fold cross-validation to select optimal tuning parameters for the model.

```{r, cache=TRUE}
fitControl <- trainControl(method="cv", number=3, verboseIter=F)
modFit <- train(classe ~ ., data=training, allowParallel=T, trControl=fitControl, method="rf")
modFit
```

```{r, cache=TRUE}
confusionMatrix(testing$classe, predict(modFit, testing))
```

The overall accuracy for Random Forest model is `0.998`.

# Parameters

# Evaluation
